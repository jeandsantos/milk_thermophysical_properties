---
title: "Modeling of the Thermophysical Properties of Milk"
subtitle: "Predicting the Heat Capacity, Thermal Conductivity and Density of Milk with Temperature, Water and Fat Content"
author: "Jean Dos Santos"
date: "14 April 2018"
output:
  rmarkdown::html_document:
    code_folding: hide
    highlight: tango
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE, 
	error = FALSE,
	comment = "",
	prompt = FALSE
)
```

***

# Objectives

The objective of this document is to develop statistical models that predict the heat capacity, thermal conductivity and density of milk with various concentrations of fat and water. Various polynomials functions were trained and tested on a training set using best subset regression and assessed using R^2^, adjusted R^2^ and cross-validation statistics using leave-one-out cross validation (LOOCV). The final models selected were assessed on a hold-out test set.

The data used for this project was obtained from the research paper [*Influence of Temperature and Water and Fat Contents on the Thermophysical Properties of Milk*](https://pubs.acs.org/doi/pdfplus/10.1021/je025546a), Minim et al., Journal of Chemical & Engineering Data 2002 47 (6), 1488-1491.


```{r, warning=FALSE, message=FALSE, prompt=FALSE, error=FALSE}
# Install and load packages
if (!require(pacman)) {install.packages("pacman")} else require(pacman)
pacman::p_load(caret, tidyverse, ggfortify, readr, readxl, parallel, doParallel, gridExtra, plyr, GGally, broom, knitr, kableExtra, tictoc, glmulti, modelr, plot3D, install = T)
```

***

# Import Data

Import dataset from CSV file:

```{r}
project_ID <- "milk_properties"
project_name <- "Milk Thermophysical Properties"

# Import data
data <- read.csv(file = "./data/Data_Milk_Thermophysical_Properties.csv", header = TRUE, row.names = NULL)

# Convert fat and water to %
data$water <- data$water*100
data$fat   <- data$fat*100

# Convert temperature from Kelvin to Celsius
data$temperature <- data$temperature - 273.15

write.csv(x = data, file = "./data/Data_Milk_Thermophysical_Properties_Transformed.csv")
```


```{r message=FALSE, warning=FALSE, message=FALSE}
# Tabulate dataset
data %>% 
  select(`Water, %` = water, `Fat, %` = fat, `Temperature, Â°C` = temperature, `Heat Capacity, J/(g.K)` = heat_capacity, `Thermal Conductivity, W/(m.K)` = thermal_conductivity, `Density, kg/m3` = density) %>% 
  kable(align = "c", caption = "Values for the Thermophysical Properties of Milk for Different Temperatures, Water and Fat Content.") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>%
  kableExtra::footnote(general = "Adapted with permission from Influence of Temperature and Water and Fat Contents on the Thermophysical Properties of Milk, Minim et al., Journal of Chemical & Engineering Data 2002 47 (6), 1488-1491. Copyright (2002) American Chemical Society.", general_title = "")
```


***

# Exploratory Data Analysis

Perform exploratory data analysis of the dataset.

## Distribution of Target Variables

The distribution of the values of each thermophysical property is plotted on the histograms below:

```{r message=FALSE, warning=FALSE, message=FALSE, fig.height=8, fig.width=5, fig.align='center'}
# Plot histograms of milk properties
g1 <- data %>% 
  ggplot(mapping = aes(x = heat_capacity)) +
    geom_histogram(bins = 10, fill = "#045a8d", alpha = 0.8) +
    labs(title = "Heat Capacity", 
         y = "Count",
         x = "Heat Capacity, J/(g.K)") +
    theme_bw() +
    theme(aspect.ratio = 0.5, legend.position = "none")

g2 <- data %>% 
  ggplot(mapping = aes(x = thermal_conductivity)) +
    geom_histogram(bins = 10, fill = "#045a8d", alpha = 0.8) +
    labs(title = "Thermal Conductivity", 
         y = "Count",
         x = "Thermal Conductivity, W/(m.K)") +
    theme_bw() +
    theme(aspect.ratio = 0.5, legend.position = "none")

g3 <- data %>% 
  ggplot(mapping = aes(x = density)) +
    geom_histogram(bins = 10, fill = "#045a8d", alpha = 0.8) +
    labs(title = "Density", 
         y = "Count",
         x = "Density, kg/m3") +
    theme_bw() +
    theme(aspect.ratio = 0.5, legend.position = "none", axis.title = element_text(size = NULL))

gridExtra::grid.arrange(g1,g2,g3,nrow = 3)
```

## Scatter Plot Matrix

Plot matrix of scatter plot to analyse relationships between variables:

```{r message=FALSE, warning=FALSE, message=FALSE, fig.height=7, fig.width=7, fig.align='center'}
EDA_data <- data
colnames(EDA_data) <- c("Water", "Fat", "Temperature", "Heat Capacity", "Thermal Conductivity", "Density")

# install.packages("GGally", verbose = FALSE, quiet = TRUE)
library(GGally, quietly = TRUE, verbose = FALSE)

# Function to add linear regression line and points to the lower half of the scatterplot matrix
regression_lines <- function(data, mapping){
  p <- ggplot(data = data, mapping = mapping) + 
    geom_point(alpha = 0.5, 
               size = 1.5, 
               color = "#08519c") + # Add points
    geom_smooth(method=lm, 
                fill="#08306b", 
                color="#08306b") # Add linear regression
  p
}

ggpairs(data = EDA_data, 
        lower = list(continuous = regression_lines)
        ) + 
  theme_bw() + 
  theme(
        panel.background = element_blank(),
        panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        axis.line = element_line(colour = "black"), axis.text = element_text(size = 6), strip.text = element_text(size = 7)
        )
```

## Correlation Heat Map

Plot correlation heat map of dataset:

```{r, fig.align='center'}
# Correlation Heat Map
ggcorr(EDA_data, label = TRUE, palette = "RdBu", name = "Correlation", hjust = 0.75, label_size = 3, label_round = 2)
```

***

# Modeling


```{r}
# Function to plot observed vs predicted values
predicted_observed_plot <- function(predicted_val, observed_val, residual_val, model_name = "", R_squared, ...) {
  
  plot <- ggplot(mapping = aes(x = predicted_val, y = observed_val, col = abs(residual_val))) +
  geom_point(alpha = 0.9, size = 2) +
  geom_abline(intercept = 0, slope = 1) +
    labs(title = paste0(model_name, "\nPredicted vs Observed: Test Set"),
         subtitle = paste0("R-squared: ", signif(R_squared, 4)),
         x = "Predicted",
         y = "Observed",
         col = "Absolute Deviation") +
  theme_bw() +
  theme(aspect.ratio = 0.9, panel.grid.minor.x = element_blank(), legend.title = element_text(size = 10, face="bold"), legend.text = element_text(size = 9), plot.title = element_text(size=12, face="bold"), axis.title=element_text(size=10, face="bold"), axis.text.x = element_text(angle = 0), legend.position = "none") +
  coord_equal() + scale_color_viridis_c(direction = -1)

  return (plot)
}

# Function to plot residuals
residuals_plot <- function(predicted_val, residual_val, model_name = "", MAE, RMSE, ...) {

  plot <- ggplot(mapping = aes(x = predicted_val, y = residual_val, col = abs(residual_val))) +
  geom_point(alpha = 0.9, size = 2) +
  geom_abline(intercept = 0, slope = 0) +
    labs(
       title = paste0(model_name, "\nResiduals: Test Set"),
       subtitle = paste0("RMSE: ", signif(RMSE, 4), ", MAE: ", signif(MAE, 4)),
       x = "Predicted",
       y = "Residual",
       col = "Absolute Deviation"
       ) +
  theme_bw() +
  theme(aspect.ratio = 0.9, panel.grid.minor.x = element_blank(), legend.title = element_text(size = 10, face="bold"), legend.text = element_text(size = 9), plot.title = element_text(size=12, face="bold"), axis.title=element_text(size=10, face="bold"), axis.text.x = element_text(angle = 0), legend.position = "none") +
  coord_equal() + scale_color_viridis_c(direction = -1)

  return (plot)
}
```

## Heat Capacity

### Creating a training and test set

Create a training and test set by randomly selecting 85% of the samples from the data for the training set and use the remaining 15% for the test set.

```{r, fig.align='center', warning=FALSE, error=FALSE, message=FALSE}
predictor_ID <- c("water", "fat", "temperature")
predictor_name <- c("Water", "Fat", "Temperature")

outcome_ID <- "heat_capacity"
outcome_name <- "Heat Capacity"
units <- "J/(g.K)"
variable_vector <- data$heat_capacity

# Remove any observations with missing values
data <- data[complete.cases(data), ]

# Average the values of replicate experiments (if present)
data <- ddply(.data = data, 
                       .variables = .(water, fat, temperature), 
                       .fun = function(x) c(heat_capacity = mean(x$heat_capacity),
                                            thermal_conductivity = mean(x$thermal_conductivity),
                                            density = mean(x$density)))

# Create training and test set using stratified partioning of outcome variable
training_fraction <- 0.85
set.seed(1); training_index <- createDataPartition(y = data$heat_capacity, p = training_fraction)[[1]]

training_set <- data[training_index, ]
test_set <- data[-training_index, ]

# Check distributtion of strength on training set
par(mfrow = c(1, 2))
hist(training_set$heat_capacity, main = "Training Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

# Check distributtion of strength on test set
hist(test_set$heat_capacity, main = "Test Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

rbind(summary(training_set$heat_capacity),summary(test_set$heat_capacity)) %>% data.frame() %>% add_column(Set = c("Training Set", "Test Set")) %>% select(Set, everything()) %>% kable(digits = 4, align = "c", caption = "Training and Test Set Statistics.", col.names = c("Set", "Minimum", "1st Quartile", "Median", "Mean", "3rd quartile", "Maximum")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F), position = "center")
```

The distribution of `r outcome_name` values on both the training and test set are similar.

### Modeling

Create formula objects for multiple linear regression with and without 2-factor interaction terms and with and without quadratic terms.

```{r}
MLR_formula <- as.formula("heat_capacity ~ water + fat + temperature")
MLR_formula_Interactions <- as.formula("heat_capacity ~ water*fat*temperature")
MLR_formula_Quadratic <- as.formula("heat_capacity ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2)")
```

#### Best Subset Regression

Perform best subset regression (with and without interaction terms) and select the best models.

```{r fig.height=6, fig.width=8, message=FALSE, warning=FALSE, comment=NULL, cache=TRUE, error=FALSE, prompt=FALSE}
set.seed(1)

# Initial Formula for Best Subset Regression
BSS_formula <- as.formula(heat_capacity ~ water + fat + temperature)

# BSS with Main effects ---------------------
# Perform best subset regression without interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_NI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 1, # Main effects only
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )

# BSS with 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_WI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )

BSS_formula_QI <- as.formula(heat_capacity ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2))

# BSS with quadratic terms and 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_QI <- glmulti::glmulti(BSS_formula_QI, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "g", # Use genetic algorithm
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )

```


```{r message=FALSE, warning=FALSE}
# Save best BSS models

# main effects 
Model_BSS_NI1 <- Models_BSS_NI@objects[[1]]
Model_BSS_NI2 <- Models_BSS_NI@objects[[2]]
Model_BSS_NI3 <- Models_BSS_NI@objects[[3]]
Model_BSS_NI4 <- Models_BSS_NI@objects[[4]]
Model_BSS_NI5 <- Models_BSS_NI@objects[[5]]

# 2-fi 
Model_BSS_WI1 <- Models_BSS_WI@objects[[1]]
Model_BSS_WI2 <- Models_BSS_WI@objects[[2]]
Model_BSS_WI3 <- Models_BSS_WI@objects[[3]]
Model_BSS_WI4 <- Models_BSS_WI@objects[[4]]
Model_BSS_WI5 <- Models_BSS_WI@objects[[5]]

# quadratic with 2-fi 
Model_BSS_QI1 <- Models_BSS_QI@objects[[1]]
Model_BSS_QI2 <- Models_BSS_QI@objects[[2]]
Model_BSS_QI3 <- Models_BSS_QI@objects[[3]]
Model_BSS_QI4 <- Models_BSS_QI@objects[[4]]
Model_BSS_QI5 <- Models_BSS_QI@objects[[5]]
```

***

#### Multiple Linear Regression

Model data with standard multiple linear regression (with and without interaction terms).

```{r}
# Formula for Multiple Linear Regression - Without Interaction Terms 
formula_Linear_NI <- as.formula(heat_capacity ~ water + fat + temperature)

# Formula for Multiple Linear Regression - With all 2-factor Interaction Terms
formula_Linear_WI <- as.formula(heat_capacity ~ water*fat + water*temperature + fat*temperature)

# Formula for Multiple Linear Regression - With all quadratic and 2-factor Interaction Terms
formula_Linear_QI <- as.formula(heat_capacity ~ water*fat + water*temperature + fat*temperature + I(water^2) + I(fat^2) + I(temperature^2))
```

**Output of multiple linear regression with main factors only:**
```{r, results='asis'}
Model_Linear_NI <- lm(formula = formula_Linear_NI, data = training_set)

glance(Model_Linear_NI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors and 2-factor interactions (2-fi):**
```{r, results='asis'}
Model_Linear_WI <- lm(formula = formula_Linear_WI, data = training_set)

glance(Model_Linear_WI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors, 2-factor interactions (2-fi) and quadratic terms:**
```{r, results='asis'}
Model_Linear_QI <- lm(formula = formula_Linear_QI, data = training_set)

glance(Model_Linear_QI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

***

### Model Evaluation

Evaluate and select models with Leave-one-out cross-validation (LOOCV)

```{r message=FALSE, warning=FALSE, cache=TRUE}
# Leave-one-out cross-validation (LOOCV)

# Linear without interactions
Model_Linear_NI_LOOCV <- train(formula_Linear_NI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_WI_LOOCV <- train(formula_Linear_WI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_QI_LOOCV <- train(formula_Linear_QI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Best Subset Regression - No Interaction Terms
Model_BSS_NI1_LOOCV <- if (length(Model_BSS_NI1$coefficients)>1) train(formula(Model_BSS_NI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI2_LOOCV <- if (length(Model_BSS_NI2$coefficients)>1) train(formula(Model_BSS_NI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI3_LOOCV <- if (length(Model_BSS_NI3$coefficients)>1) train(formula(Model_BSS_NI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI4_LOOCV <- if (length(Model_BSS_NI4$coefficients)>1) train(formula(Model_BSS_NI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI5_LOOCV <- if (length(Model_BSS_NI5$coefficients)>1) train(formula(Model_BSS_NI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms
Model_BSS_WI1_LOOCV <- if (length(Model_BSS_WI1$coefficients)>1) train(formula(Model_BSS_WI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI2_LOOCV <- if (length(Model_BSS_WI2$coefficients)>1) train(formula(Model_BSS_WI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI3_LOOCV <- if (length(Model_BSS_WI3$coefficients)>1) train(formula(Model_BSS_WI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI4_LOOCV <- if (length(Model_BSS_WI4$coefficients)>1) train(formula(Model_BSS_WI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI5_LOOCV <- if (length(Model_BSS_WI5$coefficients)>1) train(formula(Model_BSS_WI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms and Quadratic Terms
Model_BSS_QI1_LOOCV <- if (length(Model_BSS_QI1$coefficients)>1) train(formula(Model_BSS_QI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI2_LOOCV <- if (length(Model_BSS_QI2$coefficients)>1) train(formula(Model_BSS_QI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI3_LOOCV <- if (length(Model_BSS_QI3$coefficients)>1) train(formula(Model_BSS_QI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI4_LOOCV <- if (length(Model_BSS_QI4$coefficients)>1) train(formula(Model_BSS_QI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI5_LOOCV <- if (length(Model_BSS_QI5$coefficients)>1) train(formula(Model_BSS_QI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
```

***

**Summary statistics for all models evaluated:**
```{r, results='asis'}
# Summary statistics for all models evaluated
options("scipen"=100, "digits"=4)

Model_Summary <- data.frame(rbind(
  # Linear without interactions
  cbind(Model = "Model_Linear_NI", Type = "MLR Main Factors",
    glance(Model_Linear_NI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_NI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_NI_LOOCV$results[[3]]),
  
  # Linear with Interactions
  cbind(Model = "Model_Linear_WI", Type = "MLR 2-fi",
    glance(Model_Linear_WI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_WI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_WI_LOOCV$results[[3]]),

  # Best Subset Regression - No Interaction Terms
    # Model_BSS_NI1_LOOCV
  cbind(Model = "Model_BSS_NI1", Type = "BSS Main Factors",
    glance(Model_BSS_NI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI1_LOOCV$results[[3]]),
    # Model_BSS_NI2_LOOCV
  cbind(Model = "Model_BSS_NI2", Type = "BSS Main Factors",
    glance(Model_BSS_NI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI2_LOOCV$results[[3]]),
    # Model_BSS_NI3_LOOCV
  cbind(Model = "Model_BSS_NI3", Type = "BSS Main Factors",
    glance(Model_BSS_NI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI3_LOOCV$results[[3]]),
    # Model_BSS_NI4_LOOCV
  cbind(Model = "Model_BSS_NI4", Type = "BSS Main Factors",
    glance(Model_BSS_NI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI4_LOOCV$results[[3]]),
    # Model_BSS_NI5_LOOCV
  cbind(Model = "Model_BSS_NI5", Type = "BSS Main Factors",
    glance(Model_BSS_NI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI5_LOOCV$results[[3]]),

  # Best Subset Regression - With Interaction Terms
    # Model_BSS_WI1_LOOCV
  cbind(Model = "Model_BSS_WI1", Type = "BSS 2-fi",
    glance(Model_BSS_WI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI1_LOOCV$results[[3]]),
    # Model_BSS_WI2_LOOCV
  cbind(Model = "Model_BSS_WI2", Type = "BSS 2-fi",
    glance(Model_BSS_WI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI2_LOOCV$results[[3]]),
    # Model_BSS_WI3_LOOCV
  cbind(Model = "Model_BSS_WI3", Type = "BSS 2-fi",
    glance(Model_BSS_WI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI3_LOOCV$results[[3]]),
    # Model_BSS_WI4_LOOCV
  cbind(Model = "Model_BSS_WI4", Type = "BSS 2-fi",
    glance(Model_BSS_WI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI4_LOOCV$results[[3]]),
    # Model_BSS_WI5_LOOCV
  cbind(Model = "Model_BSS_WI5", Type = "BSS 2-fi",
    glance(Model_BSS_WI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI5_LOOCV$results[[3]]),
  
  # Best Subset Regression - With Interaction Terms
    # Model_BSS_QI1_LOOCV
  cbind(Model = "Model_BSS_QI1", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI1_LOOCV$results[[3]]),
    # Model_BSS_QI2_LOOCV
  cbind(Model = "Model_BSS_QI2", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI2_LOOCV$results[[3]]),
    # Model_BSS_QI3_LOOCV
  cbind(Model = "Model_BSS_QI3", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI3_LOOCV$results[[3]]),
    # Model_BSS_QI4_LOOCV
  cbind(Model = "Model_BSS_QI4", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI4_LOOCV$results[[3]]),
    # Model_BSS_QI5_LOOCV
  cbind(Model = "Model_BSS_QI5", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI5_LOOCV$results[[3]])
  )
)

Model_Summary %>% 
  kable(align = "c", digits = 4, col.names = c("Model", "Type", "R-squared", "Adjusted R-squared", "AIC", "BIC", "p-value", "RMSE (LOOCV)", "R-squared (LOOCV)")) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% footnote(general = "LOOCV: Leave-one-out cross-validation", general_title = "")
```

```{r warning=FALSE, message=FALSE,comment=NULL,prompt=FALSE, fig.align='center', fig.height=14, fig.width=8}
pallete <- c("#000000", "#5e5656", 
             "#67000d", "#a50f15", "#cb181d", "#ef3b2c", "#fb6a4a", # reds
             "#08306b", "#08519c", "#2171b5", "#4292c6", "#6baed6", # blues
             "#00441b", "#006d2c", "#238b45", "#41ab5d", "#74c476") # greens

caption <- "NI: No Interaction terms\nWI: With Interaction terms\nQI: With Quadratic and Interaction terms"

# Vector for point labels
Descriptors <- c("NI", "WI", substr(Model_Summary$Model[3:length(Model_Summary$Model)], 
                                    start = nchar(x = as.character(Model_Summary$Model[3:length(Model_Summary$Model)])), 
                                    stop = nchar(as.character(Model_Summary$Model[3:length(Model_Summary$Model)]))))

# Adjusted R-squared and AIC
g1 <- Model_Summary %>%
  ggplot(aes(x = AIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and AIC."),
         caption = caption,
         x = "AIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# Adjusted R-squared and BIC
g2 <- Model_Summary %>%
  ggplot(aes(x = BIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and BIC values."),
         caption = caption,
         x = "BIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# LOOCV R-squared and LOOCV RMSE
g3 <- Model_Summary %>%
  ggplot(aes(x =RMSE.LOOCV, y = R.Squared.LOOCV, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Cross-validated RMSE and R-squared between \nobserved and predicted values"),
         caption = caption,
         x = "RMSE (LOOCV)",
         y = "R-squared (LOOCV)") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

gridExtra::grid.arrange(g1, g2, g3, ncol = 1)
```

***

### Model Evaluation

Based on the $R^2$ from Leave-one-out cross-validation (`R.squared.LOOCV`), `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` appears to be the best model.

Based on the root-mean squared error from Leave-one-out cross-validation (`RMSE.LOOCV`), `r as.character(Model_Summary$Model[which.min(Model_Summary$RMSE.LOOCV)][[1]])` appears to be the best model.

We will select the model `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` to make our predictions for `r outcome_name `.

```{r cache=TRUE}
# Best Model
# Get descriptor best model
Best_Model_ID <- as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])
# Get type of best model
Best_Model_Type <- if_else(condition = stringr::str_detect(Best_Model_ID, pattern = "QI"), 
                           true = "BSS 2-fi and Q", 
                           false = if_else(
                             condition = str_detect(Best_Model_ID, pattern = "WI"), 
                             true = "BSS 2-fi",
                             false = "BSS Main Factors")
                           )
# Get index of best model
Best_Model_Index <- as.numeric(str_extract(Best_Model_ID, "[[:digit:]]+"))

# Automatically select best model and assign it to Model_Selected_auto - choice based on R.Squared.LOOCV
Model_Selected <- if_else(
  condition = Best_Model_Type == "BSS 2-fi and Q", 
  true = Models_BSS_QI@objects[Best_Model_Index], 
  false = if_else(
    condition = Best_Model_Type == "BSS 2-fi", 
    true = Models_BSS_WI@objects[Best_Model_Index], 
    false = Models_BSS_NI@objects[Best_Model_Index])
  )[[1]]

# Create string of model selected
Model_Selected_string <- Best_Model_ID # as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]]) 

# Generate Description for model selected
Model_Selected_Description <- paste(if_else(
                                    condition = grepl(pattern = "BSS", x = Model_Selected_string),
                                            true = "Best Subset Regression Model", 
                                            false = "Multiple Linear Regression Model"),
                                    if_else(condition = grepl(pattern = "QI", x = Model_Selected_string), 
                                            true = "with Quadratic and", 
                                            false = ""),
                                    if_else(condition = grepl(pattern = "NI", x = Model_Selected_string), 
                                            true = "without Interaction Terms", 
                                            false = "with Interaction Terms"),
                                    sep = " ") 

# Save model as RDS file
saveRDS(object = Model_Selected, file = paste("Models/",project_ID, "_", outcome_ID, "_model_selected", ".rds", sep = ""))
```

***

**Summary Statistics of selected model:**
```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, cache=TRUE, results='asis', fig.align='center'}
# Print Summary Tables for selected model
options("scipen"=10000, "digits"=5)

# Print model fit statistics
glance(Model_Selected) %>% kable(digits = 3, align = "c", col.names = c("R-squared", "Adjusted R-squared", "Sigma", "Statistic", "p-value", "df", "logLik", "AIC", "BIC","Deviance", "df Residual")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# save model fit statistics
Model_Selected_Statistics <- glance(Model_Selected)

summmary_table_Model_Selected <- summary(Model_Selected) 
summmary_table_Model_Selected <- cbind(rownames(summmary_table_Model_Selected$coefficients), as.data.frame(summmary_table_Model_Selected$coefficients))
rownames(summmary_table_Model_Selected) <- NULL
colnames(summmary_table_Model_Selected) <- c("Parameter", "Estimate", "Std Error", "Statistic", "p-value")
summmary_table_Model_Selected %>% kable(digits = 6, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# # Plot model coefficients
# ggcoef(x = Model_Selected, exponentiate = F, exclude_intercept = T, vline_color = "red", vline_linetype =  "dotted", errorbar_color = "grey10", errorbar_height = .15, mapping = aes(x = estimate, y = term, size = p.value)) + scale_size_continuous(trans = "reverse") + labs(x = "Estimate", y = NULL, size = "p-value", title = paste0(outcome_name, ": Plot of Model Coefficients")) + theme_bw()

# Plot Diagnostics for selected model
ggfortify:::autoplot.lm(Model_Selected,
         ncol = 2, alpha = 0.8,
         label.size = 3) +
  theme_bw() +
  theme(aspect.ratio = 0.8, legend.title = element_text(size = 10), legend.text = element_text(size = 8), axis.title = element_text(size = 9))

# Save relevant model statistics
r.squared <- round(glance(Model_Selected)[[1]], 3)
adj.r.squared <- round(glance(Model_Selected)[[2]], 3)
r.squared.LOOCV <- round(train(as.formula(Model_Selected), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")$results[[3]], 3)
```


**Summary Statistics of selected model on test set:**
```{r}
# Make predictions on test set
test_set$heat_capacity_predicted <- predict(Model_Selected, test_set)
# Calculate Residuals on test set
test_set$heat_capacity_residuals <- test_set$heat_capacity - test_set$heat_capacity_predicted

# Calculate test set R-squared, RMSE, MAE
R_squared <- round(cor(test_set$heat_capacity_predicted, test_set$heat_capacity), 4)
RMSE <- signif(RMSE(pred = test_set$heat_capacity_predicted, obs = test_set$heat_capacity, na.rm = T), 4)
MAE <- signif(MAE(pred = test_set$heat_capacity_predicted, obs = test_set$heat_capacity), 4)

Test_Set_Statistics <- c(RMSE, MAE, R_squared)
names(Test_Set_Statistics) <- c("RMSE", "MAE", "R-squared")

# Print table
Test_Set_Statistics %>% t() %>% 
  kable(align = "c", caption = paste0("Test set statistics of predicted ", outcome_name, ".")) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = T, position = "center")

# Plot predicted vs observed values and residuals
pred_obs_plot <- predicted_observed_plot(predicted_val = test_set$heat_capacity_predicted, observed_val = test_set$heat_capacity, residual_val = test_set$heat_capacity_residuals, R_squared = R_squared, model_name = outcome_name)

residual_plot <- residuals_plot(predicted_val = test_set$heat_capacity_predicted, observed_val = test_set$heat_capacity, residual_val = test_set$heat_capacity_residuals, MAE = MAE, RMSE = RMSE, model_name = outcome_name)

gridExtra::grid.arrange(pred_obs_plot, residual_plot, ncol = 2)
```

***

### Surface Plots


```{r message=FALSE, warning=FALSE, cache=TRUE}
# Grid Settings
z_expansion_factor <- 0.05 # Expansion factor for z-axis
theta <- c(320) # Perspective angle
theta_index <- 1
colour_range <- plot3D::ramp.col(c("#2166ac", "#b2182b")) # [TD]

# Create vectors for variables
# Number fo gridlines for x- and y-axis
grid.lines <- 21

# Create values for surface plots
water_range <- seq_range(x = data$water, n = grid.lines) # x-axis
temperature_range <- seq_range(data$temperature, n = grid.lines) # y-axis
fat_range <- unique(x = data$fat) # Column

# Create grid of variables
prediction_grid <- expand.grid(
                              temperature = temperature_range,
                              water = water_range,
                              fat = fat_range
                              )
```

```{r}
# Create data frames of values for each combination of process parameters to be plotted
# 1x3 structure
# Plot 1: Row 1, Column 1
Grid1_Row1_Column1 <- prediction_grid %>% filter(fat == fat_range[1])
# Plot 2: Row 1, Column 2
Grid1_Row1_Column2 <- prediction_grid %>% filter(fat == fat_range[2])
# Plot 3: Row 1, Column 3
Grid1_Row1_Column3 <- prediction_grid %>% filter(fat == fat_range[3])

Description_Grid1_Row1_Column1 <- paste0(outcome_name, " of Milk\nwith ", fat_range[1], "% fat")
Description_Grid1_Row1_Column2 <- paste0(outcome_name, " of Milk\nwith ", fat_range[2], "% fat")
Description_Grid1_Row1_Column3 <- paste0(outcome_name, " of Milk\nwith ", fat_range[3], "% fat")

# Use selected model to make Predictions for each grid created
# Plot 1: Row 1, Column 1
Predictions_Grid1_Row1_Column1 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column1), nrow = grid.lines, ncol = grid.lines)
# Plot 2: Row 1, Column 2
Predictions_Grid1_Row1_Column2 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column2), nrow = grid.lines, ncol = grid.lines)
# Plot 3: Row 1, Column 3
Predictions_Grid1_Row1_Column3 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column3), nrow = grid.lines, ncol = grid.lines)
```


```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, error=FALSE, fig.width=12, fig.height=4.5, fig.align='center'}
# Multiple Plots
par(mfrow = c(1, 3)) # 1x3 grid
# Chart (1,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column1,
                      facets = NA),
          main = Description_Grid1_Row1_Column1)

# Chart (2,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column2,
                      facets = NA),
          main = Description_Grid1_Row1_Column2, 
          sub = paste0("R-squared = ", r.squared, "\n",
                       "Adjusted R-squared = ", adj.r.squared, "\n",
                       "Cross-validated R-squared = ", r.squared.LOOCV))

# Chart (3,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column3,
                      facets = NA),
          main = Description_Grid1_Row1_Column3)

```


```{r eval=TRUE, include=TRUE, echo=TRUE}
# Delete obsolete models
rm(list = ls(pattern = "Model_BSS_|Model_Selected|Model_Linear_|formula_"))
rm(list = ls(pattern = "^g.{1}$|Best_Model_|Predictions_Grid|outcome_|_plot$"))
```

```{r eval=TRUE, include=FALSE, echo=FALSE}
gc(verbose = F)
```

***

## Thermal Conductivity

### Creating a training and test set

Create a training and test set by randomly selecting 85% of the samples from the data for the training set and use the remaining 15% for the test set.

```{r, fig.align='center', warning=FALSE, error=FALSE, message=FALSE}
predictor_ID <- c("water", "fat", "temperature")
predictor_name <- c("Water", "Fat", "Temperature")

outcome_ID <- "thermal_conductivity"
outcome_name <- "Thermal Conductivity"
units <- "W/(m.K)"
variable_vector <- data$thermal_conductivity

# Remove any observations with missing values
data <- data[complete.cases(data), ]

# Average the values of replicate experiments (if present)
data <- ddply(.data = data, 
                       .variables = .(water, fat, temperature), 
                       .fun = function(x) c(thermal_conductivity = mean(x$thermal_conductivity),
                                            thermal_conductivity = mean(x$thermal_conductivity),
                                            density = mean(x$density)))

# Create training and test set using stratified partioning of outcome variable
training_fraction <- 0.85
set.seed(1); training_index <- createDataPartition(y = data$thermal_conductivity, p = training_fraction)[[1]]

training_set <- data[training_index, ]
test_set <- data[-training_index, ]

# Check distributtion of strength on training set
par(mfrow = c(1, 2))
hist(training_set$thermal_conductivity, main = "Training Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

# Check distributtion of strength on test set
hist(test_set$thermal_conductivity, main = "Test Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

rbind(summary(training_set$thermal_conductivity),summary(test_set$thermal_conductivity)) %>% data.frame() %>% add_column(Set = c("Training Set", "Test Set")) %>% select(Set, everything()) %>% kable(digits = 4, align = "c", caption = "Training and Test Set Statistics.", col.names = c("Set", "Minimum", "1st Quartile", "Median", "Mean", "3rd quartile", "Maximum")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F), position = "center")
```

The distribution of `r outcome_name` values on both the training and test set are similar.

### Modelling

Create formula objects for multiple linear regression with and without 2-factor interaction terms and with and without quadratic terms.

```{r}
MLR_formula <- as.formula("thermal_conductivity ~ water + fat + temperature")
MLR_formula_Interactions <- as.formula("thermal_conductivity ~ water*fat*temperature")
MLR_formula_Quadratic <- as.formula("thermal_conductivity ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2)")
```

#### Best Subset Regression

Perform best subset regression (with and without interaction terms) and select the best models.

```{r fig.height=6, fig.width=8, message=FALSE, warning=FALSE, comment=NULL, cache=TRUE, error=FALSE, prompt=FALSE}
set.seed(1)

# Initial Formula for Best Subset Regression
BSS_formula <- as.formula(thermal_conductivity ~ water + fat + temperature)

# BSS with Main effects ---------------------
# Perform best subset regression without interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_NI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 1, # Main effects only
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )

# BSS with 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_WI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )


# plot(Models_BSS_WI, type="s", cex.axis=0.8, cex.names=0.55, sub = paste0(outcome_name, ": Best subset regression with interaction terms"), mgp=c(2,0.6,-0.4))

BSS_formula_QI <- as.formula(thermal_conductivity ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2))

# BSS with quadratic terms and 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_QI <- glmulti::glmulti(BSS_formula_QI, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "g", # Use genetic algorithm
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )


# plot(Models_BSS_QI, type="s", cex.axis=0.8, cex.names=0.55, sub = paste0(outcome_name, ": Best subset regression with quadratic and interaction terms"), mgp=c(2,0.6,-0.4))
```


```{r message=FALSE, warning=FALSE}
# Save best BSS models

# main effects models
Model_BSS_NI1 <- Models_BSS_NI@objects[[1]]
Model_BSS_NI2 <- Models_BSS_NI@objects[[2]]
Model_BSS_NI3 <- Models_BSS_NI@objects[[3]]
Model_BSS_NI4 <- Models_BSS_NI@objects[[4]]
Model_BSS_NI5 <- Models_BSS_NI@objects[[5]]

# 2-fi models
Model_BSS_WI1 <- Models_BSS_WI@objects[[1]]
Model_BSS_WI2 <- Models_BSS_WI@objects[[2]]
Model_BSS_WI3 <- Models_BSS_WI@objects[[3]]
Model_BSS_WI4 <- Models_BSS_WI@objects[[4]]
Model_BSS_WI5 <- Models_BSS_WI@objects[[5]]

# 2-fi models
Model_BSS_QI1 <- Models_BSS_QI@objects[[1]]
Model_BSS_QI2 <- Models_BSS_QI@objects[[2]]
Model_BSS_QI3 <- Models_BSS_QI@objects[[3]]
Model_BSS_QI4 <- Models_BSS_QI@objects[[4]]
Model_BSS_QI5 <- Models_BSS_QI@objects[[5]]
```

***

#### Multiple Linear Regression

Model data with standard multiple linear regression (with and without interaction terms).

```{r}
# Formula for Multiple Linear Regression - Without Interaction Terms 
formula_Linear_NI <- as.formula(thermal_conductivity ~ water + fat + temperature)

# Formula for Multiple Linear Regression - With all 2-factor Interaction Terms
formula_Linear_WI <- as.formula(thermal_conductivity ~ water*fat + water*temperature + fat*temperature)

# Formula for Multiple Linear Regression - With all quadratic and 2-factor Interaction Terms
formula_Linear_QI <- as.formula(thermal_conductivity ~ water*fat + water*temperature + fat*temperature + I(water^2) + I(fat^2) + I(temperature^2))
```

**Output of multiple linear regression with main factors only:**
```{r, results='asis'}
Model_Linear_NI <- lm(formula = formula_Linear_NI, data = training_set)

glance(Model_Linear_NI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors and 2-factor interactions (2-fi):**
```{r, results='asis'}
Model_Linear_WI <- lm(formula = formula_Linear_WI, data = training_set)

glance(Model_Linear_WI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors, 2-factor interactions (2-fi) and quadratic terms:**
```{r, results='asis'}
Model_Linear_QI <- lm(formula = formula_Linear_QI, data = training_set)

glance(Model_Linear_QI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

***

### Model Evaluation

Evaluate and select models with Leave-one-out cross-validation (LOOCV)

```{r message=FALSE, warning=FALSE, cache=TRUE}
# Leave-one-out cross-validation (LOOCV)

# Linear without interactions
Model_Linear_NI_LOOCV <- train(formula_Linear_NI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_WI_LOOCV <- train(formula_Linear_WI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_QI_LOOCV <- train(formula_Linear_QI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Best Subset Regression - No Interaction Terms
Model_BSS_NI1_LOOCV <- if (length(Model_BSS_NI1$coefficients)>1) train(formula(Model_BSS_NI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI2_LOOCV <- if (length(Model_BSS_NI2$coefficients)>1) train(formula(Model_BSS_NI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI3_LOOCV <- if (length(Model_BSS_NI3$coefficients)>1) train(formula(Model_BSS_NI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI4_LOOCV <- if (length(Model_BSS_NI4$coefficients)>1) train(formula(Model_BSS_NI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI5_LOOCV <- if (length(Model_BSS_NI5$coefficients)>1) train(formula(Model_BSS_NI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms
Model_BSS_WI1_LOOCV <- if (length(Model_BSS_WI1$coefficients)>1) train(formula(Model_BSS_WI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI2_LOOCV <- if (length(Model_BSS_WI2$coefficients)>1) train(formula(Model_BSS_WI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI3_LOOCV <- if (length(Model_BSS_WI3$coefficients)>1) train(formula(Model_BSS_WI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI4_LOOCV <- if (length(Model_BSS_WI4$coefficients)>1) train(formula(Model_BSS_WI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI5_LOOCV <- if (length(Model_BSS_WI5$coefficients)>1) train(formula(Model_BSS_WI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms and Quadratic Terms
Model_BSS_QI1_LOOCV <- if (length(Model_BSS_QI1$coefficients)>1) train(formula(Model_BSS_QI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI2_LOOCV <- if (length(Model_BSS_QI2$coefficients)>1) train(formula(Model_BSS_QI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI3_LOOCV <- if (length(Model_BSS_QI3$coefficients)>1) train(formula(Model_BSS_QI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI4_LOOCV <- if (length(Model_BSS_QI4$coefficients)>1) train(formula(Model_BSS_QI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI5_LOOCV <- if (length(Model_BSS_QI5$coefficients)>1) train(formula(Model_BSS_QI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
```

***

**Summary statistics for all models evaluated:**
```{r, results='asis'}
# Summary statistics for all models evaluated
options("scipen"=100, "digits"=4)

Model_Summary <- data.frame(rbind(
  # Linear without interactions
  cbind(Model = "Model_Linear_NI", Type = "MLR Main Factors",
    glance(Model_Linear_NI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_NI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_NI_LOOCV$results[[3]]),
  
  # Linear with Interactions
  cbind(Model = "Model_Linear_WI", Type = "MLR 2-fi",
    glance(Model_Linear_WI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_WI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_WI_LOOCV$results[[3]]),

  # Best Subset Regression - No Interaction Terms
    # Model_BSS_NI1_LOOCV
  cbind(Model = "Model_BSS_NI1", Type = "BSS Main Factors",
    glance(Model_BSS_NI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI1_LOOCV$results[[3]]),
    # Model_BSS_NI2_LOOCV
  cbind(Model = "Model_BSS_NI2", Type = "BSS Main Factors",
    glance(Model_BSS_NI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI2_LOOCV$results[[3]]),
    # Model_BSS_NI3_LOOCV
  cbind(Model = "Model_BSS_NI3", Type = "BSS Main Factors",
    glance(Model_BSS_NI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI3_LOOCV$results[[3]]),
    # Model_BSS_NI4_LOOCV
  cbind(Model = "Model_BSS_NI4", Type = "BSS Main Factors",
    glance(Model_BSS_NI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI4_LOOCV$results[[3]]),
    # Model_BSS_NI5_LOOCV
  cbind(Model = "Model_BSS_NI5", Type = "BSS Main Factors",
    glance(Model_BSS_NI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI5_LOOCV$results[[3]]),

  # Best Subset Regression - With Interaction Terms
    # Model_BSS_WI1_LOOCV
  cbind(Model = "Model_BSS_WI1", Type = "BSS 2-fi",
    glance(Model_BSS_WI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI1_LOOCV$results[[3]]),
    # Model_BSS_WI2_LOOCV
  cbind(Model = "Model_BSS_WI2", Type = "BSS 2-fi",
    glance(Model_BSS_WI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI2_LOOCV$results[[3]]),
    # Model_BSS_WI3_LOOCV
  cbind(Model = "Model_BSS_WI3", Type = "BSS 2-fi",
    glance(Model_BSS_WI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI3_LOOCV$results[[3]]),
    # Model_BSS_WI4_LOOCV
  cbind(Model = "Model_BSS_WI4", Type = "BSS 2-fi",
    glance(Model_BSS_WI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI4_LOOCV$results[[3]]),
    # Model_BSS_WI5_LOOCV
  cbind(Model = "Model_BSS_WI5", Type = "BSS 2-fi",
    glance(Model_BSS_WI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI5_LOOCV$results[[3]]),
  
  # Best Subset Regression - With Interaction Terms
    # Model_BSS_QI1_LOOCV
  cbind(Model = "Model_BSS_QI1", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI1_LOOCV$results[[3]]),
    # Model_BSS_QI2_LOOCV
  cbind(Model = "Model_BSS_QI2", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI2_LOOCV$results[[3]]),
    # Model_BSS_QI3_LOOCV
  cbind(Model = "Model_BSS_QI3", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI3_LOOCV$results[[3]]),
    # Model_BSS_QI4_LOOCV
  cbind(Model = "Model_BSS_QI4", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI4_LOOCV$results[[3]]),
    # Model_BSS_QI5_LOOCV
  cbind(Model = "Model_BSS_QI5", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI5_LOOCV$results[[3]])
  )
)

Model_Summary %>% 
  kable(align = "c", digits = 4, col.names = c("Model", "Type", "R-squared", "Adjusted R-squared", "AIC", "BIC", "p-value", "RMSE (LOOCV)", "R-squared (LOOCV)")) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% footnote(general = "LOOCV: Leave-one-out cross-validation", general_title = "")
```

```{r warning=FALSE, message=FALSE,comment=NULL,prompt=FALSE, fig.align='center', fig.height=14, fig.width=8}
pallete <- c("#000000", "#5e5656", 
             "#67000d", "#a50f15", "#cb181d", "#ef3b2c", "#fb6a4a", # reds
             "#08306b", "#08519c", "#2171b5", "#4292c6", "#6baed6", # blues
             "#00441b", "#006d2c", "#238b45", "#41ab5d", "#74c476") # greens

caption <- "NI: No Interaction terms\nWI: With Interaction terms\nQI: With Quadratic and Interaction terms"

# Vector for point labels
Descriptors <- c("NI", "WI", substr(Model_Summary$Model[3:length(Model_Summary$Model)], 
                                    start = nchar(x = as.character(Model_Summary$Model[3:length(Model_Summary$Model)])), 
                                    stop = nchar(as.character(Model_Summary$Model[3:length(Model_Summary$Model)]))))

# Adjusted R-squared and AIC
g1 <- Model_Summary %>%
  ggplot(aes(x = AIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and AIC."),
         caption = caption,
         x = "AIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# Adjusted R-squared and BIC
g2 <- Model_Summary %>%
  ggplot(aes(x = BIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and BIC values."),
         caption = caption,
         x = "BIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# LOOCV R-squared and LOOCV RMSE
g3 <- Model_Summary %>%
  ggplot(aes(x =RMSE.LOOCV, y = R.Squared.LOOCV, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Cross-validated RMSE and R-squared between \nobserved and predicted values"),
         caption = caption,
         x = "RMSE (LOOCV)",
         y = "R-squared (LOOCV)") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

gridExtra::grid.arrange(g1, g2, g3, ncol = 1)
```

***

### Model Evaluation

Based on the $R^2$ from Leave-one-out cross-validation (`R.squared.LOOCV`), `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` appears to be the best model.

Based on the root-mean squared error from Leave-one-out cross-validation (`RMSE.LOOCV`), `r as.character(Model_Summary$Model[which.min(Model_Summary$RMSE.LOOCV)][[1]])` appears to be the best model.

We will select the model `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` to make our predictions for `r outcome_name `.

```{r cache=TRUE}
# Best Model
# Get descriptor best model
Best_Model_ID <- as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])
# Get type of best model
Best_Model_Type <- if_else(condition = stringr::str_detect(Best_Model_ID, pattern = "QI"), 
                           true = "BSS 2-fi and Q", 
                           false = if_else(
                             condition = str_detect(Best_Model_ID, pattern = "WI"), 
                             true = "BSS 2-fi",
                             false = "BSS Main Factors")
                           )
# Get index of best model
Best_Model_Index <- as.numeric(str_extract(Best_Model_ID, "[[:digit:]]+"))

# Automatically select best model and assign it to Model_Selected_auto - choice based on R.Squared.LOOCV
Model_Selected <- if_else(
  condition = Best_Model_Type == "BSS 2-fi and Q", 
  true = Models_BSS_QI@objects[Best_Model_Index], 
  false = if_else(
    condition = Best_Model_Type == "BSS 2-fi", 
    true = Models_BSS_WI@objects[Best_Model_Index], 
    false = Models_BSS_NI@objects[Best_Model_Index])
  )[[1]]

# Create string of model selected
Model_Selected_string <- Best_Model_ID # as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]]) 

# Generate Description for model selected
Model_Selected_Description <- paste(if_else(
                                    condition = grepl(pattern = "BSS", x = Model_Selected_string),
                                            true = "Best Subset Regression Model", 
                                            false = "Multiple Linear Regression Model"),
                                    if_else(condition = grepl(pattern = "QI", x = Model_Selected_string), 
                                            true = "with Quadratic and", 
                                            false = ""),
                                    if_else(condition = grepl(pattern = "NI", x = Model_Selected_string), 
                                            true = "without Interaction Terms", 
                                            false = "with Interaction Terms"),
                                    sep = " ") 

# Save model as RDS file
saveRDS(object = Model_Selected, file = paste("Models/",project_ID, "_", outcome_ID, "_model_selected", ".rds", sep = ""))
```

***

**Summary Statistics of selected model:**
```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, cache=TRUE, results='asis', fig.align='center'}
# Print Summary Tables for selected model
options("scipen"=10000, "digits"=5)

# Print model fit statistics
glance(Model_Selected) %>% kable(digits = 3, align = "c", col.names = c("R-squared", "Adjusted R-squared", "Sigma", "Statistic", "p-value", "df", "logLik", "AIC", "BIC","Deviance", "df Residual")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# save model fit statistics
Model_Selected_Statistics <- glance(Model_Selected)

summmary_table_Model_Selected <- summary(Model_Selected) 
summmary_table_Model_Selected <- cbind(rownames(summmary_table_Model_Selected$coefficients), as.data.frame(summmary_table_Model_Selected$coefficients))
rownames(summmary_table_Model_Selected) <- NULL
colnames(summmary_table_Model_Selected) <- c("Parameter", "Estimate", "Std Error", "Statistic", "p-value")
summmary_table_Model_Selected %>% kable(digits = 6, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# # Plot model coefficients
# ggcoef(x = Model_Selected, exponentiate = F, exclude_intercept = T, vline_color = "red", vline_linetype =  "dotted", errorbar_color = "grey10", errorbar_height = .15, mapping = aes(x = estimate, y = term, size = p.value)) + scale_size_continuous(trans = "reverse") + labs(x = "Estimate", y = NULL, size = "p-value", title = paste0(outcome_name, ": Plot of Model Coefficients")) + theme_bw()

# Save model statistics into a csv
write_csv(x = summmary_table_Model_Selected, path = paste0("Models/",  project_ID, "_", outcome_ID, "_Model_Selected_Coefficients",".csv"), na = "NA")
write_csv(x = Model_Selected_Statistics, path = paste0("Models/",  project_ID, "_", outcome_ID, "_Model_Selected_Statistics",".csv"), na = "NA")

# Plot Diagnostics for selected model
ggfortify:::autoplot.lm(Model_Selected,
         ncol = 2, alpha = 0.8,
         label.size = 3) +
  theme_bw() +
  theme(aspect.ratio = 0.8, legend.title = element_text(size = 10), legend.text = element_text(size = 8), axis.title = element_text(size = 9))

# Save relevant model statistics
r.squared <- round(glance(Model_Selected)[[1]], 3)
adj.r.squared <- round(glance(Model_Selected)[[2]], 3)
r.squared.LOOCV <- round(train(as.formula(Model_Selected), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")$results[[3]], 3)
```

**Summary Statistics of selected model on test set:**
```{r}
# Make predictions on test set
test_set$thermal_conductivity_predicted <- predict(Model_Selected, test_set)
# Calculate Residuals on test set
test_set$thermal_conductivity_residuals <- test_set$thermal_conductivity - test_set$thermal_conductivity_predicted

# Calculate test set R-squared, RMSE, MAE
R_squared <- round(cor(test_set$thermal_conductivity_predicted, test_set$thermal_conductivity), 4)
RMSE <- signif(RMSE(pred = test_set$thermal_conductivity_predicted, obs = test_set$thermal_conductivity, na.rm = T), 4)
MAE <- signif(MAE(pred = test_set$thermal_conductivity_predicted, obs = test_set$thermal_conductivity), 4)

Test_Set_Statistics <- c(RMSE, MAE, R_squared)
names(Test_Set_Statistics) <- c("RMSE", "MAE", "R-squared")

# Print table
Test_Set_Statistics %>% t() %>% 
  kable(align = "c", caption = paste0("Test set statistics of predicted ", outcome_name, ".")) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = T, position = "center")

# Plot predicted vs observed values and residuals
pred_obs_plot <- predicted_observed_plot(predicted_val = test_set$thermal_conductivity_predicted, observed_val = test_set$thermal_conductivity, residual_val = test_set$thermal_conductivity_residuals, R_squared = R_squared, model_name = outcome_name)

residual_plot <- residuals_plot(predicted_val = test_set$thermal_conductivity_predicted, observed_val = test_set$thermal_conductivity, residual_val = test_set$thermal_conductivity_residuals, MAE = MAE, RMSE = RMSE, model_name = outcome_name)

gridExtra::grid.arrange(pred_obs_plot, residual_plot, ncol = 2)
```


***

### Surface Plots


```{r message=FALSE, warning=FALSE, cache=TRUE}
# Grid Settings
z_expansion_factor <- 0.05 # Expansion factor for z-axis
theta <- c(320) # Perspective angle
theta_index <- 1
colour_range <- plot3D::ramp.col(c("#2166ac", "#b2182b")) # [TD]

# Create vectors for variables
# Number fo gridlines for x- and y-axis
grid.lines <- 21

# Create values for surface plots
water_range <- seq_range(x = data$water, n = grid.lines) # x-axis
temperature_range <- seq_range(data$temperature, n = grid.lines) # y-axis
fat_range <- unique(x = data$fat) # Column

# Create grid of variables
prediction_grid <- expand.grid(
                              temperature = temperature_range,
                              water = water_range,
                              fat = fat_range
                              ) 
```

```{r}
# Create data frames of values for each combination of process parameters to be plotted
# 1x3 structure
# Plot 1: Row 1, Column 1
Grid1_Row1_Column1 <- prediction_grid %>% filter(fat == fat_range[1])
# Plot 2: Row 1, Column 2
Grid1_Row1_Column2 <- prediction_grid %>% filter(fat == fat_range[2])
# Plot 3: Row 1, Column 3
Grid1_Row1_Column3 <- prediction_grid %>% filter(fat == fat_range[3])

Description_Grid1_Row1_Column1 <- paste0(outcome_name, " of Milk\nwith ", fat_range[1], "% fat")
Description_Grid1_Row1_Column2 <- paste0(outcome_name, " of Milk\nwith ", fat_range[2], "% fat")
Description_Grid1_Row1_Column3 <- paste0(outcome_name, " of Milk\nwith ", fat_range[3], "% fat")

# Use selected model to make Predictions for each grid created
# Plot 1: Row 1, Column 1
Predictions_Grid1_Row1_Column1 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column1), nrow = grid.lines, ncol = grid.lines)
# Plot 2: Row 1, Column 2
Predictions_Grid1_Row1_Column2 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column2), nrow = grid.lines, ncol = grid.lines)
# Plot 3: Row 1, Column 3
Predictions_Grid1_Row1_Column3 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column3), nrow = grid.lines, ncol = grid.lines)
```


```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, error=FALSE, fig.width=12, fig.height=4.5, fig.align='center'}
# Multiple Plots
par(mfrow = c(1, 3)) # 1x3 grid
# Chart (1,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column1,
                      facets = NA),
          main = Description_Grid1_Row1_Column1)

# Chart (2,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column2,
                      facets = NA),
          main = Description_Grid1_Row1_Column2, 
          sub = paste0("R-squared = ", r.squared, "\n",
                       "Adjusted R-squared = ", adj.r.squared, "\n",
                       "Cross-validated R-squared = ", r.squared.LOOCV))

# Chart (3,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column3,
                      facets = NA),
          main = Description_Grid1_Row1_Column3)

```


```{r eval=TRUE, include=TRUE, echo=TRUE}
# Delete obsolete models
rm(list = ls(pattern = "Model_BSS_|Model_Selected|Model_Linear_|formula_"))
rm(list = ls(pattern = "^g.{1}$|Best_Model_|Predictions_Grid|outcome_|_plot$"))
```

```{r eval=TRUE, include=FALSE, echo=FALSE}
gc(verbose = F)
```

***

## Density

### Creating a training and test set

Create a training and test set by randomly selecting 85% of the samples from the data for the training set and use the remaining 15% for the test set.

```{r, fig.align='center', warning=FALSE, error=FALSE, message=FALSE}
library(caret, quietly = T, verbose = F)
library(tidyverse, quietly = T, verbose = F)
library(plyr, quietly = T, verbose = F)
library(tictoc, quietly = T, verbose = F)

predictor_ID <- c("water", "fat", "temperature")
predictor_name <- c("Water", "Fat", "Temperature")

outcome_ID <- "density"
outcome_name <- "Density"
units <- "kg/m3"
variable_vector <- data$density

# Remove any observations with missing values
data <- data[complete.cases(data), ]

# Average the values of replicate experiments (if present)
data <- ddply(.data = data, 
                       .variables = .(water, fat, temperature), 
                       .fun = function(x) c(density = mean(x$density),
                                            density = mean(x$density),
                                            density = mean(x$density)))

# Create training and test set using stratified partioning of outcome variable
training_fraction <- 0.85
set.seed(1); training_index <- createDataPartition(y = data$density, p = training_fraction)[[1]]

training_set <- data[training_index, ]
test_set <- data[-training_index, ]

# Check distributtion of strength on training set
par(mfrow = c(1, 2))
hist(training_set$density, main = "Training Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

# Check distributtion of strength on test set
hist(test_set$density, main = "Test Set", xlab = paste0(outcome_name, " ", units, ""), freq = FALSE)

rbind(summary(training_set$density),summary(test_set$density)) %>% data.frame() %>% add_column(Set = c("Training Set", "Test Set")) %>% select(Set, everything()) %>% kable(digits = 4, align = "c", caption = "Training and Test Set Statistics.", col.names = c("Set", "Minimum", "1st Quartile", "Median", "Mean", "3rd quartile", "Maximum")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F), position = "center")
```

The distribution of `r outcome_name` values on both the training and test set are similar.

### Modelling

Create formula objects for multiple linear regression with and without 2-factor interaction terms and with and without quadratic terms.

```{r}
MLR_formula <- as.formula("density ~ water + fat + temperature")
MLR_formula_Interactions <- as.formula("density ~ water*fat*temperature")
MLR_formula_Quadratic <- as.formula("density ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2)")
```

#### Best Subset Regression

Perform best subset regression (with and without interaction terms) and select the best models.

```{r fig.height=6, fig.width=8, message=FALSE, warning=FALSE, comment=NULL, cache=TRUE, error=FALSE, prompt=FALSE}
set.seed(1)

# Initial Formula for Best Subset Regression
BSS_formula <- as.formula(density ~ water + fat + temperature)

# BSS with Main effects ---------------------
# Perform best subset regression without interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_NI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 1, # Main effects only
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )


# plot(Models_BSS_NI, type="s", cex.axis=0.8, cex.names=0.8, sub = paste0(outcome_name, ": Best subset regression with main effects only"), mgp=c(2,0.6,-0.4))

# BSS with 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_WI <- glmulti::glmulti(BSS_formula, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "h", # Use exhaustive screening
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )


# plot(Models_BSS_WI, type="s", cex.axis=0.8, cex.names=0.55, sub = paste0(outcome_name, ": Best subset regression with interaction terms"), mgp=c(2,0.6,-0.4))

BSS_formula_QI <- as.formula(density ~ water + fat + temperature + I(water^2) + I(fat^2) + I(temperature^2))

# BSS with quadratic terms and 2-fi ---------------------
# Perform best subset regression with interaction terms), set seed for reproducibility
set.seed(1)
Models_BSS_QI <- glmulti::glmulti(BSS_formula_QI, data = training_set,
                                      level = 2, # 2-fi considered
                                      method = "g", # Use genetic algorithm
                                      crit = "aic", # use AIC as criterium
                                      confsetsize = 8, # Keep n best models
                                      fitfunction = "lm", plotty = F, report = F  # No plots or interim reports
                                      )


# plot(Models_BSS_QI, type="s", cex.axis=0.8, cex.names=0.55, sub = paste0(outcome_name, ": Best subset regression with quadratic and interaction terms"), mgp=c(2,0.6,-0.4))
```


```{r message=FALSE, warning=FALSE}
# Save best BSS models

# main effects models
Model_BSS_NI1 <- Models_BSS_NI@objects[[1]]
Model_BSS_NI2 <- Models_BSS_NI@objects[[2]]
Model_BSS_NI3 <- Models_BSS_NI@objects[[3]]
Model_BSS_NI4 <- Models_BSS_NI@objects[[4]]
Model_BSS_NI5 <- Models_BSS_NI@objects[[5]]

# 2-fi models
Model_BSS_WI1 <- Models_BSS_WI@objects[[1]]
Model_BSS_WI2 <- Models_BSS_WI@objects[[2]]
Model_BSS_WI3 <- Models_BSS_WI@objects[[3]]
Model_BSS_WI4 <- Models_BSS_WI@objects[[4]]
Model_BSS_WI5 <- Models_BSS_WI@objects[[5]]

# 2-fi models
Model_BSS_QI1 <- Models_BSS_QI@objects[[1]]
Model_BSS_QI2 <- Models_BSS_QI@objects[[2]]
Model_BSS_QI3 <- Models_BSS_QI@objects[[3]]
Model_BSS_QI4 <- Models_BSS_QI@objects[[4]]
Model_BSS_QI5 <- Models_BSS_QI@objects[[5]]
```

***

#### Multiple Linear Regression

Model data with standard multiple linear regression (with and without interaction terms).

```{r}
# Formula for Multiple Linear Regression - Without Interaction Terms 
formula_Linear_NI <- as.formula(density ~ water + fat + temperature)

# Formula for Multiple Linear Regression - With all 2-factor Interaction Terms
formula_Linear_WI <- as.formula(density ~ water*fat + water*temperature + fat*temperature)

# Formula for Multiple Linear Regression - With all quadratic and 2-factor Interaction Terms
formula_Linear_QI <- as.formula(density ~ water*fat + water*temperature + fat*temperature + I(water^2) + I(fat^2) + I(temperature^2))
```

**Output of multiple linear regression with main factors only:**
```{r, results='asis'}
Model_Linear_NI <- lm(formula = formula_Linear_NI, data = training_set)

glance(Model_Linear_NI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors and 2-factor interactions (2-fi):**
```{r, results='asis'}
Model_Linear_WI <- lm(formula = formula_Linear_WI, data = training_set)

glance(Model_Linear_WI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

**Output of multiple linear regression with all main factors, 2-factor interactions (2-fi) and quadratic terms:**
```{r, results='asis'}
Model_Linear_QI <- lm(formula = formula_Linear_QI, data = training_set)

glance(Model_Linear_QI) %>% kable(digits = 3, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))
```

***

### Model Evaluation

Evaluate and select models with Leave-one-out cross-validation (LOOCV)

```{r message=FALSE, warning=FALSE, cache=TRUE}
# Leave-one-out cross-validation (LOOCV)

# Linear without interactions
Model_Linear_NI_LOOCV <- train(formula_Linear_NI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_WI_LOOCV <- train(formula_Linear_WI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Linear with Interactions
Model_Linear_QI_LOOCV <- train(formula_Linear_QI, data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")

# Best Subset Regression - No Interaction Terms
Model_BSS_NI1_LOOCV <- if (length(Model_BSS_NI1$coefficients)>1) train(formula(Model_BSS_NI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI2_LOOCV <- if (length(Model_BSS_NI2$coefficients)>1) train(formula(Model_BSS_NI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI3_LOOCV <- if (length(Model_BSS_NI3$coefficients)>1) train(formula(Model_BSS_NI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI4_LOOCV <- if (length(Model_BSS_NI4$coefficients)>1) train(formula(Model_BSS_NI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_NI5_LOOCV <- if (length(Model_BSS_NI5$coefficients)>1) train(formula(Model_BSS_NI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms
Model_BSS_WI1_LOOCV <- if (length(Model_BSS_WI1$coefficients)>1) train(formula(Model_BSS_WI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI2_LOOCV <- if (length(Model_BSS_WI2$coefficients)>1) train(formula(Model_BSS_WI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI3_LOOCV <- if (length(Model_BSS_WI3$coefficients)>1) train(formula(Model_BSS_WI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI4_LOOCV <- if (length(Model_BSS_WI4$coefficients)>1) train(formula(Model_BSS_WI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_WI5_LOOCV <- if (length(Model_BSS_WI5$coefficients)>1) train(formula(Model_BSS_WI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV

# Best Subset Regression - With Interaction Terms and Quadratic Terms
Model_BSS_QI1_LOOCV <- if (length(Model_BSS_QI1$coefficients)>1) train(formula(Model_BSS_QI1), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI2_LOOCV <- if (length(Model_BSS_QI2$coefficients)>1) train(formula(Model_BSS_QI2), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI3_LOOCV <- if (length(Model_BSS_QI3$coefficients)>1) train(formula(Model_BSS_QI3), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI4_LOOCV <- if (length(Model_BSS_QI4$coefficients)>1) train(formula(Model_BSS_QI4), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
Model_BSS_QI5_LOOCV <- if (length(Model_BSS_QI5$coefficients)>1) train(formula(Model_BSS_QI5), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit") else Model_Linear_NI_LOOCV
```

***

**Summary statistics for all models evaluated:**
```{r, results='asis'}
# Summary statistics for all models evaluated
options("scipen"=100, "digits"=4)

Model_Summary <- data.frame(rbind(
  # Linear without interactions
  cbind(Model = "Model_Linear_NI", Type = "MLR Main Factors",
    glance(Model_Linear_NI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_NI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_NI_LOOCV$results[[3]]),
  
  # Linear with Interactions
  cbind(Model = "Model_Linear_WI", Type = "MLR 2-fi",
    glance(Model_Linear_WI)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_Linear_WI_LOOCV$results[[2]], `R-Squared LOOCV` = Model_Linear_WI_LOOCV$results[[3]]),

  # Best Subset Regression - No Interaction Terms
    # Model_BSS_NI1_LOOCV
  cbind(Model = "Model_BSS_NI1", Type = "BSS Main Factors",
    glance(Model_BSS_NI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI1_LOOCV$results[[3]]),
    # Model_BSS_NI2_LOOCV
  cbind(Model = "Model_BSS_NI2", Type = "BSS Main Factors",
    glance(Model_BSS_NI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI2_LOOCV$results[[3]]),
    # Model_BSS_NI3_LOOCV
  cbind(Model = "Model_BSS_NI3", Type = "BSS Main Factors",
    glance(Model_BSS_NI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI3_LOOCV$results[[3]]),
    # Model_BSS_NI4_LOOCV
  cbind(Model = "Model_BSS_NI4", Type = "BSS Main Factors",
    glance(Model_BSS_NI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI4_LOOCV$results[[3]]),
    # Model_BSS_NI5_LOOCV
  cbind(Model = "Model_BSS_NI5", Type = "BSS Main Factors",
    glance(Model_BSS_NI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_NI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_NI5_LOOCV$results[[3]]),

  # Best Subset Regression - With Interaction Terms
    # Model_BSS_WI1_LOOCV
  cbind(Model = "Model_BSS_WI1", Type = "BSS 2-fi",
    glance(Model_BSS_WI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI1_LOOCV$results[[3]]),
    # Model_BSS_WI2_LOOCV
  cbind(Model = "Model_BSS_WI2", Type = "BSS 2-fi",
    glance(Model_BSS_WI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI2_LOOCV$results[[3]]),
    # Model_BSS_WI3_LOOCV
  cbind(Model = "Model_BSS_WI3", Type = "BSS 2-fi",
    glance(Model_BSS_WI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI3_LOOCV$results[[3]]),
    # Model_BSS_WI4_LOOCV
  cbind(Model = "Model_BSS_WI4", Type = "BSS 2-fi",
    glance(Model_BSS_WI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI4_LOOCV$results[[3]]),
    # Model_BSS_WI5_LOOCV
  cbind(Model = "Model_BSS_WI5", Type = "BSS 2-fi",
    glance(Model_BSS_WI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_WI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_WI5_LOOCV$results[[3]]),
  
  # Best Subset Regression - With Interaction Terms
    # Model_BSS_QI1_LOOCV
  cbind(Model = "Model_BSS_QI1", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI1)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI1_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI1_LOOCV$results[[3]]),
    # Model_BSS_QI2_LOOCV
  cbind(Model = "Model_BSS_QI2", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI2)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI2_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI2_LOOCV$results[[3]]),
    # Model_BSS_QI3_LOOCV
  cbind(Model = "Model_BSS_QI3", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI3)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI3_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI3_LOOCV$results[[3]]),
    # Model_BSS_QI4_LOOCV
  cbind(Model = "Model_BSS_QI4", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI4)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI4_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI4_LOOCV$results[[3]]),
    # Model_BSS_QI5_LOOCV
  cbind(Model = "Model_BSS_QI5", Type = "BSS 2-fi and Q",
    glance(Model_BSS_QI5)[,c(1, 2, 8, 9, 5)], `RMSE LOOCV` = Model_BSS_QI5_LOOCV$results[[2]], `R-Squared LOOCV` = Model_BSS_QI5_LOOCV$results[[3]])
  )
)

Model_Summary %>% 
  kable(align = "c", digits = 4, col.names = c("Model", "Type", "R-squared", "Adjusted R-squared", "AIC", "BIC", "p-value", "RMSE (LOOCV)", "R-squared (LOOCV)")) %>% 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F)) %>% footnote(general = "LOOCV: Leave-one-out cross-validation", general_title = "")
```

```{r warning=FALSE, message=FALSE,comment=NULL,prompt=FALSE, fig.align='center', fig.height=14, fig.width=8}
pallete <- c("#000000", "#5e5656", 
             "#67000d", "#a50f15", "#cb181d", "#ef3b2c", "#fb6a4a", # reds
             "#08306b", "#08519c", "#2171b5", "#4292c6", "#6baed6", # blues
             "#00441b", "#006d2c", "#238b45", "#41ab5d", "#74c476") # greens

caption <- "NI: No Interaction terms\nWI: With Interaction terms\nQI: With Quadratic and Interaction terms"

# Vector for point labels
Descriptors <- c("NI", "WI", substr(Model_Summary$Model[3:length(Model_Summary$Model)], 
                                    start = nchar(x = as.character(Model_Summary$Model[3:length(Model_Summary$Model)])), 
                                    stop = nchar(as.character(Model_Summary$Model[3:length(Model_Summary$Model)]))))

# Adjusted R-squared and AIC
g1 <- Model_Summary %>%
  ggplot(aes(x = AIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and AIC."),
         caption = caption,
         x = "AIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# Adjusted R-squared and BIC
g2 <- Model_Summary %>%
  ggplot(aes(x = BIC, y = adj.r.squared, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Adjusted R-squared and BIC values."),
         caption = caption,
         x = "BIC",
         y = "Adjusted R-squared") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

# LOOCV R-squared and LOOCV RMSE
g3 <- Model_Summary %>%
  ggplot(aes(x =RMSE.LOOCV, y = R.Squared.LOOCV, col = Model)) +
    geom_point(mapping = aes(shape = Type), shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 6, alpha = 0.6, position = position_jitter(width = 0.01, height = 0.01)) +
    # geom_text(mapping = aes(label = Descriptors), col = "#000000", size = 3) + # add labels to points
    scale_y_continuous(limits = c(0,1), breaks = seq(0,1,0.10), minor_breaks = NULL) +
    labs(title = paste0(outcome_name, ": Cross-validated RMSE and R-squared between \nobserved and predicted values"),
         caption = caption,
         x = "RMSE (LOOCV)",
         y = "R-squared (LOOCV)") +
    theme_bw() +
    scale_colour_manual(values = pallete) +
    guides(col=guide_legend(ncol=2, override.aes = list(shape = c(18,18,rep(15,5), rep(16,5), rep(17,5)), size = 4))) +
    theme(aspect.ratio = 0.8)

gridExtra::grid.arrange(g1, g2, g3, ncol = 1)
```

***

### Model Evaluation

Based on the $R^2$ from Leave-one-out cross-validation (`R.squared.LOOCV`), `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` appears to be the best model.

Based on the root-mean squared error from Leave-one-out cross-validation (`RMSE.LOOCV`), `r as.character(Model_Summary$Model[which.min(Model_Summary$RMSE.LOOCV)][[1]])` appears to be the best model.

We will select the model `r as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])` to make our predictions for `r outcome_name `.

```{r cache=TRUE}
# Best Model
# Get descriptor best model
Best_Model_ID <- as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]])
# Get type of best model
Best_Model_Type <- if_else(condition = stringr::str_detect(Best_Model_ID, pattern = "QI"), 
                           true = "BSS 2-fi and Q", 
                           false = if_else(
                             condition = str_detect(Best_Model_ID, pattern = "WI"), 
                             true = "BSS 2-fi",
                             false = "BSS Main Factors")
                           )
# Get index of best model
Best_Model_Index <- as.numeric(str_extract(Best_Model_ID, "[[:digit:]]+"))

# Automatically select best model and assign it to Model_Selected_auto - choice based on R.Squared.LOOCV
Model_Selected <- if_else(
  condition = Best_Model_Type == "BSS 2-fi and Q", 
  true = Models_BSS_QI@objects[Best_Model_Index], 
  false = if_else(
    condition = Best_Model_Type == "BSS 2-fi", 
    true = Models_BSS_WI@objects[Best_Model_Index], 
    false = Models_BSS_NI@objects[Best_Model_Index])
  )[[1]]

# Create string of model selected
Model_Selected_string <- Best_Model_ID # as.character(Model_Summary$Model[which.max(Model_Summary$R.Squared.LOOCV)][[1]]) 

# Generate Description for model selected
Model_Selected_Description <- paste(if_else(
                                    condition = grepl(pattern = "BSS", x = Model_Selected_string),
                                            true = "Best Subset Regression Model", 
                                            false = "Multiple Linear Regression Model"),
                                    if_else(condition = grepl(pattern = "QI", x = Model_Selected_string), 
                                            true = "with Quadratic and", 
                                            false = ""),
                                    if_else(condition = grepl(pattern = "NI", x = Model_Selected_string), 
                                            true = "without Interaction Terms", 
                                            false = "with Interaction Terms"),
                                    sep = " ") 

# Save model as RDS file
saveRDS(object = Model_Selected, file = paste("Models/",project_ID, "_", outcome_ID, "_model_selected", ".rds", sep = ""))
```

***

**Summary Statistics of selected model:**
```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, cache=TRUE, results='asis', fig.align='center'}
# Print Summary Tables for selected model
options("scipen"=10000, "digits"=5)

# Print model fit statistics
glance(Model_Selected) %>% kable(digits = 3, align = "c", col.names = c("R-squared", "Adjusted R-squared", "Sigma", "Statistic", "p-value", "df", "logLik", "AIC", "BIC","Deviance", "df Residual")) %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# save model fit statistics
Model_Selected_Statistics <- glance(Model_Selected)

summmary_table_Model_Selected <- summary(Model_Selected) 
summmary_table_Model_Selected <- cbind(rownames(summmary_table_Model_Selected$coefficients), as.data.frame(summmary_table_Model_Selected$coefficients))
rownames(summmary_table_Model_Selected) <- NULL
colnames(summmary_table_Model_Selected) <- c("Parameter", "Estimate", "Std Error", "Statistic", "p-value")
summmary_table_Model_Selected %>% kable(digits = 6, align = "c") %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive", full_width = F))

# # Plot model coefficients
# ggcoef(x = Model_Selected, exponentiate = F, exclude_intercept = T, vline_color = "red", vline_linetype =  "dotted", errorbar_color = "grey10", errorbar_height = .15, mapping = aes(x = estimate, y = term, size = p.value)) + scale_size_continuous(trans = "reverse") + labs(x = "Estimate", y = NULL, size = "p-value", title = paste0(outcome_name, ": Plot of Model Coefficients")) + theme_bw()

# Save model statistics into a csv
write_csv(x = summmary_table_Model_Selected, path = paste0("Models/",  project_ID, "_", outcome_ID, "_Model_Selected_Coefficients",".csv"), na = "NA")
write_csv(x = Model_Selected_Statistics, path = paste0("Models/",  project_ID, "_", outcome_ID, "_Model_Selected_Statistics",".csv"), na = "NA")

# Plot Diagnostics for selected model
ggfortify:::autoplot.lm(Model_Selected,
         ncol = 2, alpha = 0.8,
         label.size = 3) +
  theme_bw() +
  theme(aspect.ratio = 0.8, legend.title = element_text(size = 10), legend.text = element_text(size = 8), axis.title = element_text(size = 9))

# Save relevant model statistics
r.squared <- round(glance(Model_Selected)[[1]], 3)
adj.r.squared <- round(glance(Model_Selected)[[2]], 3)
r.squared.LOOCV <- round(train(as.formula(Model_Selected), data = training_set, trControl=trainControl(method="LOOCV"), method="lm", na.action = "na.omit")$results[[3]], 3)
```

**Summary Statistics of selected model on test set:**
```{r}
# Make predictions on test set
test_set$density_predicted <- predict(Model_Selected, test_set)
# Calculate Residuals on test set
test_set$density_residuals <- test_set$density - test_set$density_predicted

# Calculate test set R-squared, RMSE, MAE
R_squared <- round(cor(test_set$density_predicted, test_set$density), 4)
RMSE <- signif(RMSE(pred = test_set$density_predicted, obs = test_set$density, na.rm = T), 4)
MAE <- signif(MAE(pred = test_set$density_predicted, obs = test_set$density), 4)

Test_Set_Statistics <- c(RMSE, MAE, R_squared)
names(Test_Set_Statistics) <- c("RMSE", "MAE", "R-squared")

# Print table
Test_Set_Statistics %>% t() %>% 
  kable(align = "c", caption = paste0("Test set statistics of predicted ", outcome_name, ".")) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = T, position = "center") # %>%

# Plot predicted vs observed values and residuals
pred_obs_plot <- predicted_observed_plot(predicted_val = test_set$density_predicted, observed_val = test_set$density, residual_val = test_set$density_residuals, R_squared = R_squared, model_name = outcome_name)

residual_plot <- residuals_plot(predicted_val = test_set$density_predicted, observed_val = test_set$density, residual_val = test_set$density_residuals, MAE = MAE, RMSE = RMSE, model_name = outcome_name)

gridExtra::grid.arrange(pred_obs_plot, residual_plot, ncol = 2)
```

***

### Surface Plots

```{r message=FALSE, warning=FALSE, cache=TRUE}
# Grid Settings
z_expansion_factor <- 0.05 # Expansion factor for z-axis
theta <- c(320) # Perspective angle
theta_index <- 1
colour_range <- plot3D::ramp.col(c("#2166ac", "#b2182b")) # [TD]

# Create vectors for variables
# Number fo gridlines for x- and y-axis
grid.lines <- 21

# Create values for surface plots
water_range <- seq_range(x = data$water, n = grid.lines) # x-axis
temperature_range <- seq_range(data$temperature, n = grid.lines) # y-axis
fat_range <- unique(x = data$fat) # Column

# Create grid of variables
prediction_grid <- expand.grid(
                              temperature = temperature_range,
                              water = water_range,
                              fat = fat_range
                              ) 
```

```{r}
# Create data frames of values for each combination of process parameters to be plotted
# 1x3 structure
# Plot 1: Row 1, Column 1
Grid1_Row1_Column1 <- prediction_grid %>% filter(fat == fat_range[1])
# Plot 2: Row 1, Column 2
Grid1_Row1_Column2 <- prediction_grid %>% filter(fat == fat_range[2])
# Plot 3: Row 1, Column 3
Grid1_Row1_Column3 <- prediction_grid %>% filter(fat == fat_range[3])

Description_Grid1_Row1_Column1 <- paste0(outcome_name, " of Milk\nwith ", fat_range[1], "% fat")
Description_Grid1_Row1_Column2 <- paste0(outcome_name, " of Milk\nwith ", fat_range[2], "% fat")
Description_Grid1_Row1_Column3 <- paste0(outcome_name, " of Milk\nwith ", fat_range[3], "% fat")

# Use selected model to make Predictions for each grid created
# Plot 1: Row 1, Column 1
Predictions_Grid1_Row1_Column1 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column1), nrow = grid.lines, ncol = grid.lines)
# Plot 2: Row 1, Column 2
Predictions_Grid1_Row1_Column2 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column2), nrow = grid.lines, ncol = grid.lines)
# Plot 3: Row 1, Column 3
Predictions_Grid1_Row1_Column3 <- matrix(predict(object = Model_Selected, newdata = Grid1_Row1_Column3), nrow = grid.lines, ncol = grid.lines)
```


```{r message=FALSE, warning=FALSE, comment=NULL, prompt=FALSE, error=FALSE, fig.width=12, fig.height=4.5, fig.align='center'}
# Multiple Plots
par(mfrow = c(1, 3)) # 1x3 grid
# Chart (1,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column1,
                      facets = NA),
          main = Description_Grid1_Row1_Column1)

# Chart (2,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column2,
                      facets = NA),
          main = Description_Grid1_Row1_Column2, 
          sub = paste0("R-squared = ", r.squared, "\n",
                       "Adjusted R-squared = ", adj.r.squared, "\n",
                       "Cross-validated R-squared = ", r.squared.LOOCV))

# Chart (3,1)
scatter3D(x = data$temperature,
          y = data$water,
          z = variable_vector,
          pch = 19, cex = 1.8, bty = "b2", phi = 20,
          theta = theta[[theta_index]],
          col = colour_range,
          ticktype = "detailed", colkey = FALSE, 
          xlab = "Temperature (Â°C)",
          ylab = "Water (%)",
          zlab = paste0(outcome_name, " ", units),
          xlim = c(min(data$temperature, na.rm = TRUE), max(data$temperature, na.rm = TRUE)),
          ylim = c(min(data$water, na.rm = TRUE), max(data$water, na.rm = TRUE)),
          zlim = range(min(variable_vector, na.rm = TRUE)*(1-z_expansion_factor), max(variable_vector, na.rm = TRUE)*(1+z_expansion_factor)),
          surf = list(x = temperature_range,
                      y = water_range,
                      z = Predictions_Grid1_Row1_Column3,
                      facets = NA),
          main = Description_Grid1_Row1_Column3)

```


```{r eval=TRUE, include=TRUE, echo=TRUE}
# Delete obsolete models
rm(list = ls(pattern = "Model_BSS_|Model_Selected|Model_Linear_|formula_"))
rm(list = ls(pattern = "^g.{1}$|Best_Model_|Predictions_Grid|outcome_|_plot$"))
```

```{r eval=TRUE, include=FALSE, echo=FALSE}
gc(verbose = F)
```

***

# Summary

The models obtained show that the heat capacity, thermal conductivity and density of milk can be reliably modeled with statistical models.

Temperature and water content appear to be the most important variables to predict heat capacity and thermal conductivity. Milk density seems to be mostly affected by temperature.

***

# References

[*Influence of Temperature and Water and Fat Contents on the Thermophysical Properties of Milk*](https://pubs.acs.org/doi/pdfplus/10.1021/je025546a) Luis A. Minim, Jane S. R. Coimbra, and, ValÃ©ria P. R. Minim, and Javier Telis-Romero, Journal of Chemical & Engineering Data, 2002, 47 (6), 1488-1491, DOI: 10.1021/je025546a



